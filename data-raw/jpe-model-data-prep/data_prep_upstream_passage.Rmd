---
title: "Data Prep for JPE Model"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, fig.width=15, fig.height=10)
library(tidyverse)
library(googleCloudStorageR)
library(lubridate)
color_pal <- c("#9A8822",  "#F8AFA8", "#FDDDA0", "#74A089", "#899DA4", "#446455", "#DC863B", "#C93312")
```

## Prep Adult Upstream Passage Data 


### Read in Data 
Pull data from google cloud or read in CSV if it is already on your machine 
```{r}
# Set your authentication using gcs_auth

# gcs_auth(json_file = Sys.getenv("GCS_AUTH_FILE"))
# Set global bucket
# gcs_global_bucket(bucket = Sys.getenv("GCS_DEFAULT_BUCKET"))

# download file as csv
# gcs_get_object(object_name = "/standard-format-data/standard_adult_upstream_passage.csv",
#                bucket = gcs_get_global_bucket(),
#                saveToDisk = "../../data/standard-format-data/standard_adult_upstream_passage.csv",
#                overwrite = TRUE)

standard_adult_upsream <- read_csv("../../data/standard-format-data/standard_adult_upstream_passage.csv") %>% glimpse
```

### Reformat Data for JPE 

Guidance from modeler: 
I think I will need a very simple format for adult weir count data. Fields:

Year
Count
Sex
Size (e.g. fork length)
Origin (hatchery or wild as determined by adipose fin clip)

Assuming only spring run fish are included in the count - this assumption is not correct. We will keep run in to show which tributaries give run and which they are all NA 


```{r}
model_format_upstream <- standard_adult_upsream %>% 
  mutate(year = year(date)) %>%
  select(location, year, count, run, sex, origin) %>% glimpse
```


### Explore data 

```{r}
model_format_upstream %>% 
  group_by(location, year) %>% 
  summarise(count = sum(count, na.rm = T)) %>% 
  ggplot() + 
  geom_col(aes(x = year, y = count, fill = location), position = position_dodge2(width = 0.9, preserve = "single")) + 
  labs(title = "total yearly upstream passage count") +
  scale_fill_manual(values = color_pal) + 
  theme_minimal() + 
  theme(legend.position = "bottom", 
        text = element_text(size = 18),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
```{r}
model_format_upstream %>% 
  group_by(location, year, run) %>% 
  summarise(count = sum(count, na.rm = T)) %>% 
  ggplot() + 
  geom_col(aes(x = year, y = count, fill = run), position = position_dodge2(width = 0.9, preserve = "single")) + 
  labs(title = "total yearly upstream passage count") +
  scale_fill_manual(values = color_pal) + 
  theme_minimal() + 
  theme(legend.position = "bottom", 
        text = element_text(size = 18),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + 
  facet_wrap(~location, scales = "free")
```

### Save to Google Cloud 

```{r}
clean_passage <- model_format_upstream

knitr::kable(clean_passage %>% head)
```

```{r, eval=FALSE}
# Write to google cloud 
# Name file [watershed]_[data type].csv
write_csv(clean_passage, "../../data/jpe-model-data/adult_upstream_passage.csv")
f <- function(input, output) write_csv(input, file = output)
gcs_upload(clean_passage,
           object_function = f,
           type = "csv",
           name = "jpe-model-data/adult_upstream_passage.csv")


```

