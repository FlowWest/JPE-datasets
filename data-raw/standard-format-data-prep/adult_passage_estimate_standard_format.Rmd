---
title: "adult_upstream_passage_estimates_standard_format"
output: html_document
date: "2023-02-10"
---

```{r, include = F}
library(dtplyr)
library(data.table)
library(tidyverse)
library(lubridate)
library(googleCloudStorageR)
library(knitr)
library(hms)
library(here)

root.dir <- rprojroot::find_rstudio_root_file()
knitr::opts_knit$set(root.dir)
knitr::opts_chunk$set(echo = TRUE)
```

```{r, data_pull, include = F, echo = F, eval = F}
# Data pull ---------------------------------------------------------------
gcs_auth(json_file = Sys.getenv("GCS_AUTH_FILE"))
gcs_global_bucket(bucket = Sys.getenv("GCS_DEFAULT_BUCKET"))

# pull in grandtab data. this data was extracted from https://nrm.dfg.ca.gov/FileHandler.ashx?DocumentID=84381 for spring run only
# using tabula and then cleaned up. sacramento river was not included because it is unknown where that data is coming from.
gcs_get_object(object_name = "adult-upstream-passage-monitoring/grandtab_spring.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "grandtab_spring.csv"),
               overwrite = TRUE)

# pull in standard format data to compare estimates
gcs_get_object(object_name = "standard-format-data/standard_adult_upstream_passage.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "standard_adult_upstream_passage.csv"),
               overwrite = TRUE)

# pull in battle passages estimates that were scraped from 2020 report: https://storage.cloud.google.com/jpe-dev-bucket/adult-upstream-passage-monitoring/battle-creek/data-raw/2020%20Battle%20Creek%20Adult%20Monitoring%20Report.pdf
gcs_get_object(object_name = 
                 "adult-upstream-passage-monitoring/battle-creek/data-raw/battle_spring_passage_estimates.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "battle_spring_passage_estimates.csv"),
               overwrite = TRUE)

# pull in yuba passage estimates that were pulled from https://storage.cloud.google.com/jpe-dev-bucket/adult-upstream-passage-monitoring/yuba-river/data-raw/2020%20Update%20LYR%20Chinook%20Salmon%20Run%20Differentiation_December%202020.pdf
gcs_get_object(object_name = 
                 "adult-upstream-passage-monitoring/yuba-river/data-raw/yuba_escapement_values.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "yuba_spring_passage_estimates.csv"),
               overwrite = TRUE)

# pull in butte creek vaki estimates
# https://www.calfish.org/ProgramsData/ConservationandManagement/CentralValleyMonitoring/SacramentoValleyTributaryMonitoring/ButteCreek.aspx
gcs_get_object(object_name = 
                 "adult-holding-redd-and-carcass-surveys/butte-creek/Butte_Creek_Historic_Escapement.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "butte_escapement.csv"),
               overwrite = TRUE)
```


```{r, data_pull, include = F, echo = F, eval = F}
# Deer Creek and Mill Creek files were sent individually from Doug Killam and added to the google bucket

# get filenames
get_deer_creek_filenames <- function() {
  gcs_list_objects(bucket = gcs_get_global_bucket(), 
                                         detail = "more", 
                                         prefix =  "adult-upstream-passage-monitoring/deer-creek/data-raw/DCVS") |> 
  distinct(name) |> 
    pull()
}

get_mill_creek_filenames <- function() {
  gcs_list_objects(bucket = gcs_get_global_bucket(), 
                                         detail = "more", 
                                         prefix =  "adult-upstream-passage-monitoring/mill-creek/data-raw/MCVS") |> 
  distinct(name) |> 
    pull()
}

read_from_cloud <- function(file_name){
  if(str_detect(file_name, "deer")) {
    output_dir = "data-raw/qc-markdowns/adult-upstream-passage-monitoring/deer-creek/"
  } else if(str_detect(file_name, "mill")) {
    output_dir = "data-raw/qc-markdowns/adult-upstream-passage-monitoring/mill-creek/"
  }
  
  file_title <- basename(file_name) # remove full path
  
  gcs_get_object(object_name = file_name,
                 bucket = gcs_get_global_bucket(),
                 saveToDisk = paste0(output_dir, file_title),
                 overwrite = TRUE)
}

# pull from cloud
purrr::map(get_deer_creek_filenames(), read_from_cloud)
purrr::map(get_mill_creek_filenames(), read_from_cloud)

```

# Deer Creek Passage Estimates

- Deer Creek has passage estimates from 2013-2023. Doug Killam (Doug.Killam@wildlife.ca.gov) is the contact and provided individual data sheets with the raw and interpolated counts for each year. They are in slightly different formats based on the year.
- Deer Creek has estimates by ladder (North and South)

## 2013-2014
```{r}
deer_creek_files <- basename(get_deer_creek_filenames())
deer_2014_raw <- readxl::read_xls(here("data-raw", "qc-markdowns", "adult-upstream-passage-monitoring", "deer-creek", paste0(deer_creek_files[1]))) 

deer_2014 <- deer_2013_raw |>
  select(main_col = `Deer Creek Video Station Final Counts February 20, 2014 through June 30, 2014.`) |> 
  filter(!is.na(main_col)) |> 
  mutate(ladder = case_when(str_detect(main_col, "South") ~ "south",
                            str_detect(main_col, "North") ~ "north",
                            TRUE ~ NA),
         is_estimate = ifelse(str_detect(main_col, "Estimat"), TRUE, FALSE),
         is_count = ifelse(str_detect(main_col, "Count"), TRUE, FALSE),
         is_confidence_interval = ifelse(str_detect(main_col, "Confidence"), TRUE, FALSE),
         species = case_when(str_detect(main_col, "Chinook") ~ "chinook",
                             str_detect(main_col, "Steelhead") ~ "steelhead", 
                             TRUE ~ NA)) |> 
    filter(is_estimate | is_count | is_confidence_interval) |> 
  mutate(abundance_estimate = ifelse(is_estimate, readr::parse_number(main_col), NA),
         count = ifelse(is_count, readr::parse_number(main_col), NA),
         cls_raw = str_remove(main_col, "90 %"),
         cls = gsub("[^0-9.-]", "", cls_raw)) |> 
  separate(cls, into = c("lcl", "ucl"), sep = "-") |> 
  fill(species) |> 
  fill(ladder) |> 
  mutate(lcl = as.numeric(lcl),
         ucl = as.numeric(ucl)) |> 
  filter(species == "chinook") |> 
  select(abundance_estimate, lcl, ucl, ladder) |> 
  fill(abundance_estimate) |> 
  filter(!is.na(ucl)) |> 
  mutate(year = 2014,
         stream = "deer creek",
         confidence_interval = "90") |> 
  select(year, stream, ladder, abundance_estimate, lcl, ucl, confidence_interval)
```

## 2016-2017

```{r}
deer_2017_raw <- openxlsx::read.xlsx(here("data-raw", "qc-markdowns", "adult-upstream-passage-monitoring", "deer-creek", paste0(deer_creek_files[3])),
                                    rows = 1:9,
                                    fillMergedCells = TRUE,
                                    sheet = "SUMMARY") 

deer_2017 <- deer_2017_raw |> 
  rename(description = `2016-17.Deer.Creek.Spring.Video.Station.Estimate`,
         value = X2) |> 
  mutate(data_type = case_when(str_detect(description, "Estimate") ~ "abundance_estimate",
                               str_detect(description,"lower confidence") ~ "lcl",
                               str_detect(description,"upper confidence") ~ "ucl",
                               TRUE ~ NA)) |> 
  filter(!is.na(data_type)) |> 
  select(data_type, value) |> 
  pivot_wider(values_from = value, names_from = data_type) |> 
  mutate(ladder = "both",
         stream = "deer creek",
         year = 2017,
         confidence_interval = "90")
```

```{r}
spring_grandtab <- read_csv(here::here("data", "grandtab_spring.csv"))
adult_passage_standard <- read_csv(here::here("data", "standard_adult_upstream_passage.csv"))
battle_spring <- read_csv(here::here("data", "battle_spring_passage_estimates.csv")) |> 
  rename(year = `...1`)
yuba <- read_csv(here::here("data", "yuba_spring_passage_estimates.csv"))
# need to pull vaki numbers
butte <- read_csv(here::here("data", "butte_escapement.csv")) |> 
  select(Year, Vaki) |> 
  filter(!is.na(Vaki))
```

```{r, include = F}
# what is in grandtab is exactly the same as what is in the report for battle creek
compare_battle <- left_join(spring_grandtab, battle_spring) |> 
  select(year, battle, passage_estimate)
# for the years where does has passage estimates, passage estimate data is very similar
# to what is in grandtab, there are a few discrepancies
# we aren't missing any days though so assume that we have estimates rather than raw
standard_deer <- filter(adult_passage_standard, stream == "Deer Creek") |> 
  mutate(year = year(date),
         month = month(date),
         day = day(date),
         fake_date = as_date(paste0("2000-0",month,"-",day)))
standard_deer_annual <- standard_deer |> 
  group_by(year) |> 
  summarize(count = sum(count))
compare_deer <- select(spring_grandtab, year, deer) |> 
  left_join(standard_deer_annual)

ggplot(standard_deer, aes(x = fake_date, y = count)) +
  geom_point() + 
  facet_wrap(~year)

# manual check to see if missing dates
# dates <- seq(as.Date("2000-02-01"), as.Date("2000-08-01"), by = "day")
# missing_date <- tibble(all_date = rep(dates,7),
#                        year = c(rep(2014,183), rep(2015, 183), rep(2016, 183), rep(2017, 183), rep(2018, 183), rep(2019, 183), rep(2020, 183)))
# 
# check <- full_join(standard_deer, missing_date, by = c("fake_date"="all_date", "year"))

# there are some discrepancies between the passage estimate data we have
# and what is in grandtab
standard_mill <- filter(adult_passage_standard, stream == "Mill Creek") |> 
  mutate(year = year(date),
         month = month(date),
         day = day(date),
         fake_date = as_date(paste0("2000-0",month,"-",day)))
standard_mill_annual <- standard_mill |> 
  group_by(year) |> 
  summarize(count = sum(count))
compare_mill <- select(spring_grandtab, year, mill) |> 
  left_join(standard_mill_annual)
# check <- full_join(standard_mill, missing_date, by = c("fake_date"="all_date", "year"))

# looks like yuba doesn't really report to grandtab
compare_yuba <- left_join(spring_grandtab, yuba) |> 
  select(year, yuba, spring_run_escapement)
```

Conclusions based on comparisons:
- use grandtab for battle, clear
- use standard adult data for deer, mill
- yuba we will pull from report

# Create table of annual passage estimates by stream

```{r}
# decided to remove years prior to 1994 because all NA

# pull data from grandtab because it matches the data in the battle report
# and is easier to process from grandtab
clear_battle <- select(spring_grandtab, year, battle, clear) |> 
  rename(`battle creek` = battle,
         `clear creek` = clear) |> 
  pivot_longer(cols = c("battle creek","clear creek"), names_to = "stream", values_to = "passage_estimate") |> 
  filter(year >= 1995) |> 
  mutate(run = "spring",
         adipose_clipped = F)

# data are from data provided by ryan and are all spring run. grandtab includes
# long time series so can't be sure what the data source is
deer_mill <- filter(adult_passage_standard, stream %in% c("Deer Creek", "Mill Creek")) |> 
  mutate(stream = tolower(stream),
         year = year(date)) |> 
  group_by(stream, year) |> 
  summarize(passage_estimate = sum(count)) |> 
  filter(!is.na(year), !is.na(passage_estimate)) |> 
  mutate(run = "spring",
         adipose_clipped = F)

# from report provided by yuba
yuba <- select(yuba, year, spring_run_escapement) |> 
  rename(passage_estimate = spring_run_escapement) |> 
  mutate(stream = "yuba river") |> 
  mutate(run = "spring",
         adipose_clipped = F)

# no interpolation for butte creek - raw data counts, so no uncertainty
butte <- butte |> 
  rename(year = Year,
         passage_estimate = Vaki) |> 
  mutate(stream = "butte creek") |> 
  mutate(run = "spring",
         adipose_clipped = F)

passage_estimate <- bind_rows(clear_battle,
                              deer_mill,
                              yuba,
                              butte) |> 
  mutate(passage_estimate = round(passage_estimate, 2))

write_csv(passage_estimate, here::here("data","adult_passage_estimate.csv"))
```


### Get CIs from Deer Creek raw files
```{r}
# TODO make this into a cleaner function
deer_CIs_21_22_south <- readxl::read_xlsx(here::here("data", "deer_escapement_estimates_21-22.xlsx"),
                                    sheet = "Post R DSVS Salmon ",
                                    range = "A1:F4") |> 
  filter(`2021-22  Deer Creek SPRING Video Station Estimate` == "0.9") |> 
  select(lower = `...4`, upper = `South Salmon`) |> 
  mutate(lower = as.numeric(lower), 
         upper = as.numeric(upper),
         ladder = "South")

deer_CIs_21_22_north <- readxl::read_xlsx(here::here("data", "deer_escapement_estimates_21-22.xlsx"),
                                          sheet = "Post R DNVS Salmon",
                                          range = "A1:F4") |> 
  filter(`2021-22  Deer Creek SPRING Video Station Estimate` == "0.9") |> 
  select(lower = `...4`, upper = `North Salmon`) |> 
  mutate(lower = as.numeric(lower), 
         upper = as.numeric(upper),
         ladder = "North") |> 
  bind_rows(deer_CIs_21_22_south) |> 
  glimpse()

mill_CIs_21_22 <- readxl::read_xlsx(here::here("data", "mill_escapement_estimates_21-22.xlsx"),
                                    sheet = "Post R MCVS Salmon ",
                                    range = "A1:F4") |> 
  filter(`2021-22  Mill Creek SPRING Video Station Estimate` == "0.9") |> 
  select(lower = `...4`, upper = `POST -R`) |> 
  mutate(upper = as.numeric(upper),
         lower = as.numeric(lower)) 

```

```{r, save_data}
f <- function(input, output) write_csv(input, file = output)

gcs_upload(passage_estimate,
           object_function = f,
           type = "csv",
           name = "standard-format-data/standard_adult_passage_estimate.csv",
           predefinedAcl = "bucketLevel")
```