---
title: "Feather Carcass QC 2016"
author: "Inigo Peng"
date: '2022-07-21'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, fig.width=15, fig.height=10)

library(tidyverse)
library(lubridate)
library(googleCloudStorageR)
library(ggplot2)
library(scales)
library(readxl)
library(janitor)
library(hms) #?as_hms()
library(RODBC)
library(knitr)
```

# Feather River Carcass Data

## Description of Monitoring Data

**Timeframe:** 

**Video Season:** 

**Completeness of Record throughout timeframe:** 

**Sampling Location:**

**Data Contact:** 

Any additional info?

## Access Cloud Data

```{r, eval=FALSE}
# Run Sys.setenv() to specify GCS_AUTH_FILE and GCS_DEFAULT_BUCKET before running 
# getwd() to see how to specify paths 
# Open object from google cloud storage
# Set your authentication using gcs_auth
Sys.setenv("GCS_AUTH_FILE" = "C:/Users/InigoPeng/Projects/jpe/JPE-datasets/config.json")
Sys.setenv("GCS_DEFAULT_BUCKET" = "jpe-dev-bucket")

gcs_auth(json_file = Sys.getenv("GCS_AUTH_FILE"))
# Set global bucket 
gcs_global_bucket(bucket = Sys.getenv("GCS_DEFAULT_BUCKET"))

# git data and save as xlsx
```

Read in data from google cloud, glimpse raw data and domain description sheet: 

```{r}
# knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

# Google Cloud Set up
# Sys.setenv("GCS_AUTH_FILE" = "config.json")
# Sys.setenv("GCS_DEFAULT_BUCKET" = "jpe-dev-bucket")
# 
gcs_get_object(object_name = "adult-holding-redd-and-carcass-surveys/feather-river/data-raw/carcass/2016/ChopHeader_2016.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = "ChopHeader_2016.csv",
               overwrite = TRUE)

gcs_get_object(object_name = "adult-holding-redd-and-carcass-surveys/feather-river/data-raw/carcass/2016/Chops_2016.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = "Chops_2016.csv",
               overwrite = TRUE)

# gcs_get_object(object_name = "adult-holding-redd-and-carcass-surveys/feather-river/data-raw/carcass/ChopRecovTBL.xlsx",
#                bucket = gcs_get_global_bucket(),
#                saveToDisk = "ChopRecovTBL.xlsx",
#                overwrite = TRUE)

# Read Data
# this is our main data collection table
# Channel section is included
Chop_2016_raw <- read_csv("Chops_2016.csv") %>% 
  rename("ID" = Chop.Header.ID,
         "Count" = Total.Count) %>%
  glimpse()


# This is a survey info table
ChopHeader_2016_raw <- read_csv("ChopHeader.csv") %>% 
  rename("ID" = Chop.Header.ID,
         "Week" = Week..) %>%
  glimpse()

#There are not as much information 
```

```{r}
# TODO: Attempt, but not needed
# from ashley: this is code to read in tables from Access. Have you figured out 
# how to get this to work on your machine?

# library(Hmisc)
# 
# # List of all available tables
# mdb.get("CAMP_Escapement_20210412.mdb")
# 
# # Code to read in the CatchRaw table
# carcasschops <- mdb.get("CAMP_DB_for_FlowWest/CAMP_Escapement_20210412.mdb", tables = "CarcassChops")
# 

```

## Data transformations

```{r}
# 1. we need to link chopheader and chop to get the dates and time 
# 2. dropping Chop.ID from Chop_2016_raw (whole column null)
# 3. Do we need weather, crew and comments from Chop.Header

chop_join <- left_join(ChopHeader_2016_raw %>% 
                                 select(ID, Date, Time),
                               Chop_2016_raw %>% 
                         select(-Chop.ID)) %>% 
  clean_names()

chop_header <- ChopHeader_2016_raw %>% 
  clean_names()

```

### Counts

The `chop` table contains carcass counts

### Survey

The `chop_header` table contains survey metadata and covariates


## Explore Numeric Variables: {.tabset}

```{r}
# Filter clean data to show only numeric variables 
chop_join %>% 
  select_if(is.numeric) %>%
  colnames()
```

### Variable: `id`, `section`, `min`

```{r}
summary(chop_join$id)
```
```{r}
summary(chop_join$section)
```

```{r}
summary(chop_join$minutes)
```


### Variable: `count`

**Numeric Summary of `count` over Period of Record**


```{r}
summary(chop_join$count)
```

**NA and Unknown Values**

* `r round(sum(is.na(chop_join$count))/nrow(chop_join), 3) * 100` % of values in the `count` column are NA.

**Plotting count over Period of Record**

```{r}

# daily chop count over time
chop_join %>% 
  ggplot(aes(x = date, y = count)) +
  geom_point() + 
  theme_minimal() +
  theme(text = element_text(size = 15))
```

This plot shows the daily chops collected each day from August to December 2016. The data from 2016 does not contain tags information - it only has count.

**Plotting total chops over Period of Record**

```{r}
chop_join %>% 
  group_by(date) %>% 
  summarize(total_chops = sum(count, na.rm = T)) %>% 
  ggplot(aes(x = date, y = total_chops)) + 
  geom_col() + 
  theme_minimal()
```

This plot shows the daily total chops collected between August and December.

```{r}
#Chop header table only has one numeric variable

chop_header %>% 
  select_if(is.numeric) %>%
  colnames()
```

```{r}
summary(chop_header$id)
```


## Explore Categorical variables: {.tabset}

```{r}
# Filter clean data to show only categorical variables
#Chops table has no categorical variables
chop_header %>% 
  select_if(is.character) %>%
  colnames()
```

## Clean data

Fix inconsistencies with spelling, capitalization, and dates

```{r}
chop_join_cleaner <- chop_join %>% 
  mutate_if(is.character, str_to_lower) %>% 
  mutate(datetime = ymd_hms(paste(date, time))) %>% 
  select(-c(date, time))

chop_join_cleaner

chop_header_cleaner <- chop_header %>% 
  mutate_if(is.character, str_to_lower) %>% 
  mutate(crew = str_replace(crew, ",,", ","),
         datetime = ymd_hms(paste(date, time))) %>% 
  select(-c(date, time, week))

chop_header_cleaner
```

## Data Dictionaries

### Chop Count

```{r}
percent_na <- chop_join_cleaner %>%
  summarise_all(list(name = ~sum(is.na(.))/length(.))) %>%
  pivot_longer(cols = everything())


counts_data_dictionary <- tibble(variables = colnames(chop_join_cleaner),
                          description = c("ID",
                                          "Sect",
                                          "Min", 
                                          "Carcass chopped count",
                                          "Datetime of the survey"),
                          percent_na = round(percent_na$value*100,
                                             digits = 1))

kable(counts_data_dictionary)
```

### Survey

```{r}
percent_na <- chop_header_cleaner %>%
  summarise_all(list(name = ~sum(is.na(.))/length(.))) %>%
  pivot_longer(cols = everything())

header_data_dictionary <- tibble(variables = colnames(chop_header_cleaner),
                          description = c("Weather",
                                          "Crew memeber initials that collected",
                                          "Comments",
                                          "ID",
                                          "Datetime"),
                          percent_na = round(percent_na$value*100,
                                             digits = 1))

kable(header_data_dictionary)
```

## Save cleaned data back to google cloud (TBA)

```{r}
# Name file [watershed]_[data type].csv
```


