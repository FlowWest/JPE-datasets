---
title: "Feather River RST Catch Data QC"
author: "Erin Cain"
date: "9/29/2021"
output: rmarkdown::github_document
---
  
```{r setup, include=FALSE, fig.width=15, fig.height=10}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(tidyverse)
library(lubridate)
library(googleCloudStorageR)
library(ggplot2)
library(scales)
library(readxl)
```

# Feather River RST Catch Data

## Description of Monitoring Data

Background: The traps are typically operated for approximately seven months (December through June). Two trap locations are necessary because flow is strictly regulated above the Thermalito Outlet and therefore emigration cues and species composition may be different for the two reaches.

**Timeframe:** Dec 1997 - May 2021
  
**Trapping Season:** Typically December - June, looks like it varies quite a bit. 
  
**Completeness of Record throughout timeframe:** 
  
**Sampling Location:**
Two RST locations are generally used, one at the lower end of each of the two study reaches. Typically, one RST is stationed at the bottom of Eye Side Channel, RM 60.2 (approximately one mile above the Thermalito Afterbay Outlet) and one stationed in the HFC below Herringer riffle, at RM 45.7.

TODO if time add map with sites here
  
**Data Contact:** 
[Kassie Hickey](mailto:KHickey@psmfc.org)
  
## Access Cloud Data
  
```{r, eval=FALSE}
# Run Sys.setenv() to specify GCS_AUTH_FILE and GCS_DEFAULT_BUCKET before running 
# getwd() to see how to specify paths 
# Open object from google cloud storage
# Set your authentication using gcs_auth
gcs_auth(json_file = Sys.getenv("GCS_AUTH_FILE"))
# Set global bucket 
gcs_global_bucket(bucket = Sys.getenv("GCS_DEFAULT_BUCKET"))

gcs_list_objects()
# git data and save as xlsx
gcs_get_object(object_name = "rst/feather-river/data-raw/Feather River RST Natural Origin Chinook Catch Data_1998-2021.xlsx",
               bucket = gcs_get_global_bucket(),
               saveToDisk = "raw_feather_rst_data.xlsx",
               overwrite = TRUE)

```

Read in data from google cloud, glimpse raw data and domain description sheet: 
```{r}
# read in data to clean
# RST Data
rst_data_sheets <- readxl::excel_sheets("raw_feather_rst_data.xlsx")
survey_year_details  <- readxl::read_excel("raw_feather_rst_data.xlsx", 
                                           sheet = "Survey Year Details") 
survey_year_details
# create function to read in all sheets of a 
read_sheets <- function(sheet){
  data <- read_excel("raw_feather_rst_data.xlsx", sheet = sheet)
}

raw_catch <- purrr::map(rst_data_sheets[-1], read_sheets) %>%
    reduce(bind_rows)

raw_catch %>% glimpse()
```

## Data transformations

```{r}
# Snake case, 
# Columns are appropriate types
# Remove redundant columns
cleaner_catch_data <- raw_catch %>%
  rename("date" = Date, "site_name" = siteName, 
         "at_capture_run" = `At Capture Run`, 
         "lifestage" = lifeStage, 
         "fork_length" = FL, "count" = n) %>%
  mutate(date = as.Date(date)) %>%
  filter(commonName == "Chinook salmon") %>%
  select(-commonName)

cleaner_catch_data %>% glimpse()
```

## Explore Numeric Variables: {.tabset}

```{r}
# Filter clean data to show only numeric variables 
cleaner_catch_data %>% select_if(is.numeric) %>% colnames()
```

### Variable: `fork_length`

**Plotting fork_length at RST sites**
  
```{r}
# Make whatever plot is appropriate 
# maybe 2 plots is appropriate
cleaner_catch_data %>% 
  ggplot(aes(x = fork_length, y = site_name)) + 
  geom_boxplot() + 
  theme_minimal() +
  labs(title = "Fork length summarized by site") + 
  theme(text = element_text(size = 15),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 
```

**Numeric Summary of fork_length over Period of Record**
  
```{r}
# Table with summary statistics
summary(cleaner_catch_data$fork_length)
```

**NA and Unknown Values**
  
* `r round(sum(is.na(cleaner_catch_data$fork_length))/nrow(cleaner_catch_data), 3) * 100` % of values in the `fork_length` column are NA. 

### Variable: `count`

**Plotting passage counts over period of reccord**
```{r}
cleaner_catch_data %>% 
  mutate(year = as.factor(year(date)),
         fake_date = as.Date(paste0("1900-", month(date), "-", day(date)))) %>%
  ggplot(aes(x = fake_date, y = count, color = year)) + 
  geom_line() + 
  # facet_wrap(~year(date), scales = "free") + 
  scale_x_date(labels = date_format("%b"), date_breaks = "1 month") + 
  theme_minimal() + 
  theme(text = element_text(size = 15),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.position = "bottom") + 
  labs(title = "Daily Count of Fish Passage (1997-2021)")  

```
  
```{r}
# Make whatever plot is appropriate 
# maybe 2 plots is appropriate
cleaner_catch_data %>% 
  mutate(year = as.factor(year(date))) %>%
  ggplot(aes(x = count, y = year)) + 
  geom_boxplot() + 
  theme_minimal() +
  labs(title = "Passage count summarized by year") + 
  theme(text = element_text(size = 15),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 
```

**Numeric Summary of count over Period of Record**
  
```{r}
# Table with summary statistics
summary(cleaner_catch_data$count)
```

**NA and Unknown Values**
  
* `r round(sum(is.na(cleaner_catch_data$count))/nrow(cleaner_catch_data), 3) * 100` % of values in the `count` column are NA. 

## Explore Categorical variables: {.tabset}

General notes: If there is an opportunity to turn yes no into boolean do so, but not if you loose value 


```{r}
# Filter clean data to show only categorical variables (this way we know we do not miss any)
cleaner_catch_data %>% select_if(is.character) %>% colnames()
```


### Variable: `site_name`
```{r}
table(cleaner_catch_data$site_name) 
```



**Create location lookup rda for site_name:** 
TODO 
```{r}
# Create named lookup vector
# Name rda [watershed]_[data type]_[variable_name].rda
# save rda to data/ 
```

**NA and Unknown Values**
  
* `r round(sum(is.na(cleaner_catch_data$site_name))/nrow(cleaner_catch_data), 3) * 100` % of values in the `site_name` column are NA. 

### Variable: `at_capture_run`
```{r}
table(cleaner_catch_data$at_capture_run) 
cleaner_catch_data$at_capture_run <- ifelse(cleaner_catch_data$at_capture_run == "Not recorded", NA, tolower(cleaner_catch_data$at_capture_run))
```

**NA and Unknown Values**
  
* `r round(sum(is.na(cleaner_catch_data$at_capture_run))/nrow(cleaner_catch_data), 3) * 100` % of values in the `at_capture_run` column are NA. 

### Variable: `lifestage`
```{r}
table(cleaner_catch_data$lifestage) 
cleaner_catch_data$lifestage <- ifelse(cleaner_catch_data$lifestage == "Not recorded", NA, tolower(cleaner_catch_data$lifestage))
```

**NA and Unknown Values**
  
* `r round(sum(is.na(cleaner_catch_data$lifestage))/nrow(cleaner_catch_data), 3) * 100` % of values in the `lifestage` column are NA. 

```{r}
feather_rst <- cleaner_catch_data %>% glimpse()
```

### Save cleaned data back to google cloud 

```{r, eval=FALSE}
# Write to google cloud 
# Name file [watershed]_[data type].csv
f <- function(input, output) write_csv(input, file = output)

gcs_upload(feather_rst,
           object_function = f,
           type = "csv",
           name = "rst/feather-river/data/feather_rst.csv")
```
